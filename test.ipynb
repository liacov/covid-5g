{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_gexf('data/net_5gANDcovid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5g': 297,\n",
       " 'coronavirus': 234,\n",
       " 'covid19': 112,\n",
       " 'cina': 31,\n",
       " 'iot': 28,\n",
       " 'wuhan': 22,\n",
       " 'tecnologia': 22,\n",
       " 'robot': 22,\n",
       " 'usa': 22,\n",
       " 'italia': 22,\n",
       " 'smartcity': 21,\n",
       " 'verizon': 21,\n",
       " 'snapdragon': 20,\n",
       " 'guidaautonoma': 19,\n",
       " 'selfdrivingcars': 19,\n",
       " 'ai': 19,\n",
       " 'autonomousvehicles': 19,\n",
       " 'selfdriving': 19,\n",
       " 'autonomous': 19,\n",
       " 'robotics': 19}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg = dict(graph.degree)\n",
    "{k: deg[k] for k in sorted(deg, key=deg.get, reverse=True)[:20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_edgelist(graph,'data/net_5gANDcovid_edgelist',delimiter=',',data=['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_lines\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df_cov, df_5g = pd.DataFrame(),pd.DataFrame()\n",
    "\n",
    "\n",
    "def parse_tweet(retrieved_tweet, datetime_format='%a %b %d %H:%M:%S %z %Y'):\n",
    "    # Initialize parsed tweet object\n",
    "    parsed_tweet = dict()\n",
    "    # Get tweet id\n",
    "    parsed_tweet['tweet_id'] = str(retrieved_tweet.get('id_str'))\n",
    "    # Get tweet date\n",
    "    parsed_tweet['tweet_date'] = datetime.strptime(\n",
    "        retrieved_tweet.get('created_at'),\n",
    "        datetime_format\n",
    "    )\n",
    "    # Initialize parsed tweet text\n",
    "    tweet_text = ''\n",
    "    # Case tweet is a retweet\n",
    "    if 'retweeted_status' in set(retrieved_tweet.keys()):\n",
    "        # Get inner tweet\n",
    "        retrieved_tweet = retrieved_tweet['retweeted_status']\n",
    "    # Check if current tweet is an extended tweet\n",
    "    if 'extended_tweet' in set(retrieved_tweet.keys()):\n",
    "        tweet_text = retrieved_tweet['extended_tweet']['full_text']\n",
    "    # Case current tweet is not an extended one\n",
    "    else:\n",
    "        tweet_text = retrieved_tweet['text']\n",
    "    # Store tweet text\n",
    "    parsed_tweet['tweet_text'] = tweet_text\n",
    "    # Return tweet\n",
    "    return parsed_tweet\n",
    "\n",
    "tweets = list()\n",
    "# Load input file\n",
    "with open('./data/20200215_only_5g_it.jsonl', 'rb') as in_file:\n",
    "    # Loop through each line in input .jsonl formatted file\n",
    "    for retrieved_tweet in json_lines.reader(in_file, broken=True):\n",
    "        # Format retrieved tweet according to inner DataFrame\n",
    "        parsed_tweet = parse_tweet(retrieved_tweet)\n",
    "        # Append parsed tweet to tweets list\n",
    "        tweets.append(parsed_tweet)\n",
    "# Append list of retrieved tweets to inner Dataframe\n",
    "df_5g = df_5g.append(tweets, ignore_index=True)\n",
    "\n",
    "tweets = list()\n",
    "# Load input file\n",
    "with open('./data/20200215_only_covid_it.jsonl', 'rb') as in_file:\n",
    "    # Loop through each line in input .jsonl formatted file\n",
    "    for retrieved_tweet in json_lines.reader(in_file, broken=True):\n",
    "        # Format retrieved tweet according to inner DataFrame\n",
    "        parsed_tweet = parse_tweet(retrieved_tweet)\n",
    "        # Append parsed tweet to tweets list\n",
    "        tweets.append(parsed_tweet)\n",
    "# Append list of retrieved tweets to inner Dataframe\n",
    "df_cov = df_cov.append(tweets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4349, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciaolei'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "s = 'ciao 12 ?lei'\n",
    "s = re.sub('\\d','',s)\n",
    "re.sub(r'[^\\w-]','', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
